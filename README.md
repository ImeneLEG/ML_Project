# ğŸ“§ Projet Machine Learning : DÃ©tection de Spam et Ham dans les e-mails

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du Mini-Projet de Machine Learning Ã  l'ENSAO par le groupe **[SPAM/HAM Team]** composÃ© des Ã©tudiants suivants :

| Nom et PrÃ©nom       | Profil GitHub       |
|---------------------|---------------------|
| Imane LEGSIR        | [Imane Legsir](https://github.com/ImeneLEG) ğŸ‘©â€ğŸ’» |
| Nousseiba ZAOUI     | [nousseibazaoui](lien_vers_profil) ğŸ‘©â€ğŸ’» |
| Hajar DOBLI         | [hajardobli](https://github.com/HajarDobli) ğŸ‘©â€ğŸ’» |
| Kaoutar LAOUAJ      | [kaoutarlaouaj](https://github.com/Kaoutarlaouaj) ğŸ‘©â€ğŸ’» |
| Manal BENDALI       | [manalbendali](https://github.com/manalbendali) ğŸ‘©â€ğŸ’» |
| Doha ANIBA          | [Doha Aniba](https://github.com/Dohaaniba) ğŸ‘©â€ğŸ’» |

#  Introduction

Dans un monde oÃ¹ la communication Ã©lectronique est omniprÃ©sente, la dÃ©tection de spam est d'une importance cruciale. Les e-mails non sollicitÃ©s peuvent constituer une menace pour la sÃ©curitÃ©, la confidentialitÃ© et l'efficacitÃ© des utilisateurs. Ce projet vise Ã  dÃ©velopper un modÃ¨le de Machine Learning capable de distinguer les e-mails spam (indÃ©sirables) des e-mails lÃ©gitimes (ham).

# ğŸ“ Organisation des fichiers

### ğŸ“„ **Code source du projet :** 
ğŸ”— [**Lien vers le code source**](Copie_de_Project_Machine_Learning.ipynb) 

### ğŸ“Š **Dataset :** 
ğŸ”— [**Lien vers le dataset** (From Kaggle)](spam_ham_dataset.csv) 

### ğŸ“‘ **Rapport :** 
ğŸ”— [**Lien vers le rapport**](Rapport_Spam&Ham_Preject.pdf) 

# ğŸ“š BibliothÃ¨ques nÃ©cessaires

Pour exÃ©cuter le code, assurez-vous d'avoir les bibliothÃ¨ques Python suivantes installÃ©es :

- **pandas:** UtilisÃ© pour la manipulation et l'analyse des donnÃ©es tabulaires.
- **scikit-learn (sklearn):** UtilisÃ© pour la modÃ©lisation des donnÃ©es et les outils d'Ã©valuation des modÃ¨les.
- **matplotlib:** UtilisÃ© pour la visualisation des donnÃ©es et des rÃ©sultats.
- **seaborn:** Ã‰galement utilisÃ© pour la visualisation des donnÃ©es.
- **nltk:** UtilisÃ© pour le traitement naturel du langage (NLP), notamment la tokenization et le tÃ©lÃ©chargement de certains ensembles de donnÃ©es (stopwords, punkt).
- **WordCloud:** Une bibliothÃ¨que Python pour la crÃ©ation de nuages de mots Ã  partir de textes. Elle permet de visualiser les mots les plus frÃ©quents dans un texte en les affichant dans une disposition visuellement attrayante.

## ğŸ› ï¸ Vous pouvez les installer en utilisant la commande suivante :

```bash
pip install pandas scikit-learn matplotlib seaborn nltk wordcloud
