# Projet Machine Learning : Détection de Spam et Ham dans les e-mails

Ce projet a été réalisé dans le cadre du Mini-Projet de Machine Learning à l'ENSAO par le groupe **[SPAM/HAM Team]** composé des étudiants suivants :

| Nom et Prénom       | Profil GitHub       |
|---------------------|---------------------|
| Imane LEGSIR        | [Imane Legsir ](https://github.com/ImeneLEG) |
| Nousseiba ZAOUI     | [nousseibazaoui](lien_vers_profil) |
| Hajar DOBLI         | [hajardobli](https://github.com/HajarDobli) |
| Kaoutar LAOUAJ      | [kaoutarlaouaj](https://github.com/Kaoutarlaouaj) |
| Manal BENDALI       | [manalbendali](https://github.com/manalbendali) |
| Doha ANIBA          | [Doha Aniba](https://github.com/Dohaaniba) |


# Introduction

Dans un monde où la communication électronique est omniprésente, la détection de spam est d'une importance cruciale. Les e-mails non sollicités peuvent constituer une menace pour la sécurité, la confidentialité et l'efficacité des utilisateurs. Ce projet vise à développer un modèle de Machine Learning capable de distinguer les e-mails spam (indésirables) des e-mails légitimes (ham).

# Organisation des fichiers

### - **Code source du projet :** Le code source est disponible dans le fichier Jupyter Notebook.
=> [**Lien vers le code source**](Copie_de_Project_Machine_Learning.ipynb)
### - **Dataset :** Nous avons utilisé le jeu de données disponible sur Kaggle. 
=> [**Lien vers le dataset** (From Kaggle)](spam_ham_dataset.csv)
### - **Rapport :** Le rapport complet du projet est disponible dans le fichier. 
=> [**Lien vers le rapport**](Rapport_Spam&Ham_Preject.pdf)

# Bibliothèques nécessaires

Pour exécuter le code, assurez-vous d'avoir les bibliothèques Python suivantes installées :

-**pandas:** Utilisé pour la manipulation et l'analyse des données tabulaires.

-**scikit-learn (sklearn):** Utilisé pour la modélisation des données et les outils d'évaluation des modèles.

-**matplotlib:** Utilisé pour la visualisation des données et des résultats.

-**seaborn:** Également utilisé pour la visualisation des données.

-**nltk:** Utilisé pour le traitement naturel du langage (NLP), notamment la tokenization et le téléchargement de certains ensembles de données (stopwords, punkt).

-**WordCloud:** Une bibliothèque Python pour la création de nuages de mots à partir de textes. Elle permet de visualiser les mots les plus fréquents dans un texte en les affichant dans une disposition visuellement attrayante.

## Vous pouvez les installer en utilisant la commande suivante :

```bash
pip install pandas scikit-learn matplotlib seaborn nltk wordcloud

